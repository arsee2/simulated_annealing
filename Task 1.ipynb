{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from tensorflow.python.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "import copy\n",
    "min_T = 0.00001\n",
    "\n",
    "def annealing(func,x,T):\n",
    "    '''\n",
    "    func - h function\n",
    "    x - argument \n",
    "    T - temperature\n",
    "    return p(x)\n",
    "    '''\n",
    "    return np.power(np.e,(-func(x)/T))\n",
    "\n",
    "def sa_algorithm(func, g_x, n, max_iter=300, an_rate=0.99):\n",
    "    '''\n",
    "    func - function to optimize\n",
    "    g_x - proposed distribution\n",
    "    max_iter - maximum number of iterations\n",
    "    an_rate - annealing rate\n",
    "    '''\n",
    "    x_t = np.random.random(n)-1 # uniform [-0.5;0.5]\n",
    "    global_sol = copy.deepcopy(x_t)\n",
    "    T = 2000\n",
    "    for iter in range(max_iter):\n",
    "        x = g_x(x_t)\n",
    "        alpha = annealing(func,x,T)/annealing(func,x_t,T)\n",
    "        if (np.random.random()<=alpha): \n",
    "            x_t = copy.deepcopy(x)\n",
    "        if func(global_sol)>=func(x_t): # update global min\n",
    "            global_sol =copy.deepcopy(x_t)\n",
    "        T = T*an_rate\n",
    "        if T < min_T:\n",
    "            break\n",
    "    \n",
    "    return global_sol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model):\n",
    "    return accuracy_score(y_test,np.argmax(model.predict(X_test),axis=1))\n",
    "\n",
    "def train_accuracy(model):\n",
    "    return accuracy_score(y_train,np.argmax(model.predict(X_train),axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time s:  3.7916128635406494\n",
      "Train accuracy using backpropagation:  0.9583333333333334\n",
      "Test accuracy using backpropagation:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=4, activation='relu'))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "st = time.time()\n",
    "model.fit(X_train,to_categorical(y_train),epochs=300,verbose = False)\n",
    "print(\"Time s: \",  time.time()-st)\n",
    "print(\"Train accuracy using backpropagation: \",train_accuracy(model))\n",
    "print(\"Test accuracy using backpropagation: \",test_accuracy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_g_x(n):\n",
    "    return lambda x: np.random.normal(x,1,n)\n",
    "\n",
    "def set_params(x,model):\n",
    "    '''\n",
    "    x - params\n",
    "    nn - neural network model\n",
    "    '''\n",
    "    \n",
    "    new_weights=[]\n",
    "    current =0 # current weights\n",
    "    for weight in model.get_weights():\n",
    "        nps = np.prod(weight.shape) #number of parameters\n",
    "        new_weights.append(np.reshape(x[current:current+nps],weight.shape))\n",
    "        current+=nps\n",
    "        \n",
    "    model.set_weights(new_weights)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "def cross_entropy(predictions, targets, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions. \n",
    "    Input: predictions (N, k) ndarray\n",
    "           targets (N, k) ndarray        \n",
    "    Returns: scalar\n",
    "    \"\"\"\n",
    "    predictions = np.clip(predictions, epsilon, 1. - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets*np.log(predictions+1e-9))/N\n",
    "    return ce\n",
    "\n",
    "def loss(x):\n",
    "\n",
    "    '''\n",
    "    This is the function that will be optimized.\n",
    "    x - parameters\n",
    "    '''\n",
    "    set_params(x,model)\n",
    "    y = model.predict(X_train)\n",
    "    loss_value = cross_entropy(to_categorical(y_train),y)\n",
    "   \n",
    "    \n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time s: 45.54397130012512\n",
      "Annealing rate 0.999, train accuracy: 0.6583333333333333\n",
      "Annealing rate 0.999, test accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "best_params = sa_algorithm(loss,get_g_x(model.count_params()),model.count_params(),an_rate=0.999)\n",
    "set_params(best_params,model)\n",
    "print(\"Time s:\", time.time()-st)\n",
    "print(\"Annealing rate 0.999, train accuracy:\",train_accuracy(model))\n",
    "print(\"Annealing rate 0.999, test accuracy:\",test_accuracy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time s: 46.19804787635803\n",
      "Annealing rate 0.99, train accuracy: 0.6666666666666666\n",
      "Annealing rate 0.99, test accuracy: 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "best_params = sa_algorithm(loss,get_g_x(model.count_params()),model.count_params(),an_rate=0.99)\n",
    "set_params(best_params,model)\n",
    "print(\"Time s:\", time.time()-st)\n",
    "print(\"Annealing rate 0.99, train accuracy:\",train_accuracy(model))\n",
    "print(\"Annealing rate 0.99, test accuracy:\",test_accuracy(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsee\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annealing rate 0.90, train accuracy: 0.675\n",
      "Annealing rate 0.90, test accuracy: 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "best_params = sa_algorithm(loss,get_g_x(model.count_params()),model.count_params(),an_rate=0.9)\n",
    "print(\"Annealing rate 0.90, train accuracy:\",train_accuracy(model))\n",
    "print(\"Annealing rate 0.90, test accuracy:\",test_accuracy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsee\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annealing rate 0.8, train accuracy: 0.5666666666666667\n",
      "Annealing rate 0.8, test accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "best_params = sa_algorithm(loss,get_g_x(model.count_params()),model.count_params(),an_rate=0.8)\n",
    "print(\"Annealing rate 0.8, train accuracy:\",train_accuracy(model))\n",
    "print(\"Annealing rate 0.8, test accuracy:\",test_accuracy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arsee\\Anaconda3\\envs\\keras_env\\lib\\site-packages\\ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annealing rate 0.5, train accuracy: 0.3333333333333333\n",
      "Annealing rate 0.5, test accuracy: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "best_params = sa_algorithm(loss,get_g_x(model.count_params()),model.count_params(),an_rate=0.5)\n",
    "print(\"Annealing rate 0.5, train accuracy:\",train_accuracy(model))\n",
    "print(\"Annealing rate 0.5, test accuracy:\",test_accuracy(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
